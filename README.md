# RAG System - Production-Ready Retrieval Augmented Generation

A production-grade RAG system built with Docker microservices, Azure OpenAI, and PostgreSQL. Features include agentic query processing, hybrid search, document intelligence, and a full admin UI.

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         DOCKER COMPOSE                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ Frontend â”‚  â”‚ Backend  â”‚  â”‚ Ingestionâ”‚  â”‚  Query   â”‚       â”‚
â”‚  â”‚  (React) â”‚  â”‚  (API)   â”‚  â”‚  Worker  â”‚  â”‚  Worker  â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜       â”‚
â”‚       â”‚             â”‚             â”‚             â”‚              â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                     â”‚             â”‚                            â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â”                       â”‚
â”‚              â”‚  RabbitMQ   â”‚  â”‚ Qdrant â”‚                       â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                                                                 â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚
â”‚              â”‚  PostgreSQL â”‚                                   â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚        Azure Cloud Services           â”‚
              â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
              â”‚  â”‚  OpenAI   â”‚  â”‚   Document     â”‚   â”‚
              â”‚  â”‚  Service  â”‚  â”‚  Intelligence  â”‚   â”‚
              â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Features

### Core Capabilities
- **Document Ingestion**: 7-stage pipeline (OCR, Vision, Tree Building, Enrichment, Chunking, Embeddings, Storage)
- **Agentic Query Processing**: Iterative query refinement with up to 3 iterations
- **Hybrid Search**: RRF-based fusion of vector and keyword search
- **Admin UI**: React-based interface for document management and debugging

### Production Features
- âœ… JSON structured logging with request/correlation ID tracking
- âœ… PostgreSQL-based rate limiting (no Redis dependency)
- âœ… Global error handling with consistent JSON responses
- âœ… Health checks for all services
- âœ… Async/await throughout for performance
- âœ… Type hints and Pydantic validation
- âœ… Dockerized deployment

## Quick Start

### Prerequisites
- Docker & Docker Compose
- Azure OpenAI subscription
- Azure Document Intelligence subscription

### Setup

1. **Clone and configure**
   ```bash
   git clone <repository>
   cd RAG_System
   cp .env.example .env
   ```

2. **Edit `.env` with your Azure credentials**
   ```env
   AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
   AZURE_OPENAI_API_KEY=your_key_here
   AZURE_DOC_INTELLIGENCE_ENDPOINT=https://your-resource.cognitiveservices.azure.com/
   AZURE_DOC_INTELLIGENCE_KEY=your_key_here
   POSTGRES_USER=rag_user
   POSTGRES_PASSWORD=your_secure_password
   ```

3. **Start all services**
   ```bash
   docker-compose up --build
   ```

4. **Access the application**
   - Frontend: http://localhost:3000
   - Backend API: http://localhost:8000
   - API Docs: http://localhost:8000/docs
   - RabbitMQ Management: http://localhost:15672 (guest/guest)
   - Qdrant Dashboard: http://localhost:6333/dashboard

## Project Structure

```
RAG_System/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env.example
â”œâ”€â”€ init-db.sql
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ config.py                    # Pydantic settings
â”‚   â”‚   â”œâ”€â”€ main.py                      # FastAPI app
â”‚   â”‚   â”œâ”€â”€ dependencies.py              # DI container
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”‚   â”œâ”€â”€ logging.py               # JSON structured logging
â”‚   â”‚   â”‚   â”œâ”€â”€ exceptions.py            # Custom exceptions
â”‚   â”‚   â”‚   â””â”€â”€ constants.py             # System constants
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â”œâ”€â”€ database.py              # SQLAlchemy models
â”‚   â”‚   â”‚   â”œâ”€â”€ schemas.py               # Pydantic schemas
â”‚   â”‚   â”‚   â””â”€â”€ enums.py                 # Status enums
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”œâ”€â”€ middleware/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ logging.py           # Request/response logging
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ rate_limit.py        # PostgreSQL rate limiter
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ error_handler.py     # Global error handler
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â””â”€â”€ routes/
â”‚   â”‚   â”‚       â”œâ”€â”€ health.py            # Health checks
â”‚   â”‚   â”‚       â”œâ”€â”€ documents.py         # Document endpoints
â”‚   â”‚   â”‚       â”œâ”€â”€ queries.py           # Query endpoints
â”‚   â”‚   â”‚       â””â”€â”€ settings.py          # Settings endpoints
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ repositories/
â”‚   â”‚   â”‚   â”œâ”€â”€ document_repository.py   # Document CRUD
â”‚   â”‚   â”‚   â”œâ”€â”€ query_repository.py      # Query CRUD
â”‚   â”‚   â”‚   â””â”€â”€ settings_repository.py   # Settings CRUD
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ services/
â”‚   â”‚       â”œâ”€â”€ document_service.py      # Document business logic
â”‚   â”‚       â”œâ”€â”€ query_service.py         # Query business logic
â”‚   â”‚       â”œâ”€â”€ queue_service.py         # RabbitMQ operations
â”‚   â”‚       â””â”€â”€ settings_service.py      # Settings management
â”‚   â”‚
â”‚   â””â”€â”€ tests/
â”‚
â”œâ”€â”€ workers/
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ main.py                  # Worker entry point
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py                # Worker config
â”‚   â”‚   â”‚   â”œâ”€â”€ consumer.py              # RabbitMQ consumer
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ pipeline/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ document_intelligence.py  # Azure Document Intelligence
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ vision_processor.py       # GPT-4 Vision
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tree_builder.py           # Document tree
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ enrichment.py             # Summary & Q&A
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ chunker.py                # Semantic chunking
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ embedder.py               # Embedding generation
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â””â”€â”€ storage/
â”‚   â”‚   â”‚       â”œâ”€â”€ qdrant_client.py     # Vector storage
â”‚   â”‚   â”‚       â””â”€â”€ postgres_client.py   # Metadata storage
â”‚   â”‚
â”‚   â””â”€â”€ query/
â”‚       â”œâ”€â”€ Dockerfile
â”‚       â”œâ”€â”€ requirements.txt
â”‚       â”œâ”€â”€ src/
â”‚       â”‚   â”œâ”€â”€ main.py
â”‚       â”‚   â”œâ”€â”€ config.py
â”‚       â”‚   â”œâ”€â”€ consumer.py
â”‚       â”‚   â”‚
â”‚       â”‚   â”œâ”€â”€ pipeline/
â”‚       â”‚   â”‚   â”œâ”€â”€ embedder.py          # Query embedding
â”‚       â”‚   â”‚   â”œâ”€â”€ retriever.py         # Hybrid search
â”‚       â”‚   â”‚   â”œâ”€â”€ reranker.py          # Result reranking
â”‚       â”‚   â”‚   â”œâ”€â”€ agent.py             # Agentic evaluation
â”‚       â”‚   â”‚   â””â”€â”€ generator.py         # Answer generation
â”‚       â”‚   â”‚
â”‚       â”‚   â””â”€â”€ storage/
â”‚       â”‚       â””â”€â”€ qdrant_client.py     # RRF hybrid search
â”‚
â””â”€â”€ frontend/
    â”œâ”€â”€ Dockerfile
    â”œâ”€â”€ package.json
    â”œâ”€â”€ tsconfig.json
    â”œâ”€â”€ tailwind.config.js
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ App.tsx
    â”‚   â”‚
    â”‚   â”œâ”€â”€ pages/
    â”‚   â”‚   â”œâ”€â”€ Settings.tsx             # Azure config & RAG settings
    â”‚   â”‚   â”œâ”€â”€ Documents.tsx            # Document management
    â”‚   â”‚   â””â”€â”€ Query.tsx                # Query & debug interface
    â”‚   â”‚
    â”‚   â”œâ”€â”€ components/
    â”‚   â”‚   â”œâ”€â”€ DocumentUpload.tsx
    â”‚   â”‚   â”œâ”€â”€ DocumentList.tsx
    â”‚   â”‚   â”œâ”€â”€ DocumentDetails.tsx
    â”‚   â”‚   â”œâ”€â”€ ChunksViewer.tsx
    â”‚   â”‚   â”œâ”€â”€ AnswerDisplay.tsx
    â”‚   â”‚   â””â”€â”€ DebugPanel.tsx           # Iteration debug info
    â”‚   â”‚
    â”‚   â”œâ”€â”€ hooks/
    â”‚   â”‚   â”œâ”€â”€ useDocuments.ts
    â”‚   â”‚   â””â”€â”€ useQuery.ts
    â”‚   â”‚
    â”‚   â”œâ”€â”€ services/
    â”‚   â”‚   â””â”€â”€ api.ts                   # Axios API client
    â”‚   â”‚
    â”‚   â””â”€â”€ types/
    â”‚       â””â”€â”€ index.ts
```

## API Endpoints

### Documents
- `POST /documents/upload` - Upload document
- `GET /documents` - List all documents
- `GET /documents/{id}` - Get document details
- `GET /documents/{id}/chunks` - Get document chunks
- `DELETE /documents/{id}` - Delete document

### Queries
- `POST /queries` - Submit query
- `GET /queries/{id}` - Get query result

### Settings
- `GET /settings` - Get current settings
- `PUT /settings` - Update settings

### Health
- `GET /health` - Overall health status

## Ingestion Pipeline

The document ingestion pipeline consists of 7 stages:

1. **Azure Document Intelligence**: Extract document structure (pages, paragraphs, tables, images)
2. **Vision Processing**: OCR and semantic description of images using GPT-4 Vision
3. **Tree Building**: Build unified document tree merging text and image descriptions
4. **Enrichment**: Generate document summary and Q&A pairs using Azure OpenAI LLM
5. **Semantic Chunking**: Language-aware chunking respecting sentence boundaries
6. **Embedding Generation**: Generate embeddings using text-embedding-3-large
7. **Storage**: Store chunks, summaries, Q&A in Qdrant and update PostgreSQL metadata

## Query Pipeline

The agentic query pipeline:

1. **Embed Query**: Generate query embedding
2. **Hybrid Search**: RRF-based fusion of vector and keyword search
3. **Rerank**: Rerank results using cross-encoder or LLM
4. **Agent Evaluation**: Evaluate context sufficiency
   - PROCEED: Generate answer
   - REFINE_QUERY: Modify query and retry
   - EXPAND_SEARCH: Broaden search and retry
5. **Generation**: Generate answer with citations

Maximum 3 iterations with full debug tracking.

## Environment Variables

See `.env.example` for all configuration options.

### Required
- `AZURE_OPENAI_ENDPOINT` - Azure OpenAI service endpoint
- `AZURE_OPENAI_API_KEY` - Azure OpenAI API key
- `AZURE_DOC_INTELLIGENCE_ENDPOINT` - Azure Document Intelligence endpoint
- `AZURE_DOC_INTELLIGENCE_KEY` - Azure Document Intelligence API key
- `POSTGRES_USER` - PostgreSQL username
- `POSTGRES_PASSWORD` - PostgreSQL password

### Optional (with defaults)
- `AZURE_EMBEDDING_DEPLOYMENT` - Embedding model (default: text-embedding-3-large)
- `AZURE_LLM_DEPLOYMENT` - LLM model (default: gpt-4)
- `DEFAULT_TOP_K` - Initial retrieval count (default: 10)
- `DEFAULT_RERANK_TOP` - Post-rerank count (default: 5)
- `MAX_AGENT_ITERATIONS` - Max query iterations (default: 3)
- `CHUNK_SIZE` - Chunk size in tokens (default: 512)
- `CHUNK_OVERLAP` - Chunk overlap (default: 50)
- `RATE_LIMIT_PER_MINUTE` - Rate limit (default: 60)

## Development

### Running locally (without Docker)

**Backend:**
```bash
cd backend
pip install -r requirements.txt
uvicorn src.main:app --reload
```

**Ingestion Worker:**
```bash
cd workers/ingestion
pip install -r requirements.txt
python src/main.py
```

**Query Worker:**
```bash
cd workers/query
pip install -r requirements.txt
python src/main.py
```

**Frontend:**
```bash
cd frontend
npm install
npm start
```

### Testing
```bash
cd backend
pytest tests/
```

## Troubleshooting

### Services won't start
- Check Docker is running: `docker info`
- Check logs: `docker-compose logs -f <service-name>`
- Verify .env file has all required variables

### Connection errors
- Ensure all services are healthy: `docker-compose ps`
- Check service health: `curl http://localhost:8000/health`
- Verify network connectivity between containers

### Rate limiting
- Rate limits are per IP address or API key
- Current limits: 60 requests/minute, 1000 requests/hour
- Adjust in .env: `RATE_LIMIT_PER_MINUTE` and `RATE_LIMIT_PER_HOUR`

## Monitoring

### Logs
All services use JSON structured logging:
```bash
docker-compose logs -f backend
docker-compose logs -f ingestion-worker
docker-compose logs -f query-worker
```

### Metrics
- Request IDs track requests across services
- Correlation IDs trace distributed workflows
- Response time headers on all API responses

## Contributing

This is a production-ready template. Customize as needed:
1. Add authentication/authorization
2. Implement backup/restore procedures
3. Add monitoring (Prometheus, Grafana)
4. Set up CI/CD pipelines
5. Configure SSL/TLS
6. Add distributed tracing

## License

MIT License - See LICENSE file for details

## Status

**Current Implementation:**
- âœ… Infrastructure (Docker Compose, PostgreSQL, Qdrant, RabbitMQ)
- âœ… Core utilities (Logging, Exceptions, Configuration)
- âœ… Database models and schemas
- âœ… Middleware stack (Logging, Rate Limiting, Error Handling)
- ğŸš§ Repository layer (In Progress)
- ğŸš§ Service layer (In Progress)
- ğŸš§ API routes (In Progress)
- ğŸ“‹ Workers (Pending)
- ğŸ“‹ Frontend (Pending)

**Next Steps:**
1. Complete backend API (repositories, services, routes)
2. Implement ingestion worker pipeline
3. Implement query worker pipeline
4. Build React frontend
5. End-to-end testing
